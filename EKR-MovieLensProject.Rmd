---
title: "MovieLens Dataset Analysis"
author: "E.K. RIHANI"
date: "07/10/2021"
output: pdf_document
---

```{r setup, include=FALSE}
load("EKR-MovieLens.RData")
knitr::opts_chunk$set(echo = TRUE)
```



# Overview

## Goal of the study
The aim of this study is to analyze a MovieLens dataset and try to create a model that can predict users' future preferences based on their cuent preferences, using data analysis and machine learning techniques. 

## The dataset
The MovieLens datasets were created by the GroupLens research lab, from the Department of Computer Science and Engineering at the University of Minnesota.
The dataset used for this study is the 10M dataset ([link](https://grouplens.org/datasets/movielens/10m/).
The 10M MovieLens dataset contains `r total_number_ratings` ratings for `r total_number_movies` movies, from `r total_number_users` users.  
The provided information inclue the user unique ID (`r column_names[1]`), the movie unique ID (`r column_names[2]`), the rating given by the user (`r column_names[3]`), the timestamp of the rating (`r column_names[4]`), the title of the movie (`r column_names[5]`) and its genre (`r column_names[6]`).


```{r cars}
summary(cars)
```
# Methods and Analysis
This project will aim to progressively improve the accuracy of our predictions, step by step, by building a model based on the data of a training set (edx, 90% of the database, selected randomly) and then applying this model to predict the values of a validation set (10% of the database) and compare our prediction against the actual value.  
The metric used in this study to evaluate the accuracy of the prediction is the root-mean-squared error (RMSE), given by $\sqrt{ \frac{1}{N} \sum_{u,i}(\hat{y}_{u,i} -  y_{u,i})^{2}}$ with N the number of ratings, $\hat{y}_{u,i}$ the rating that is predicted by the model built with the training set and $y_{u,i}$ the actual rating of the testing set. The lower the RMSE, the more accurate our model.  

The most basic model is a naive model that calculates the mean rating of our testing set ($\hat{\mu}$) and then applies this rating to all predictions ($\mathbf{Y}_{u,i} = \mu + \varepsilon_{u,i}$), with no distinction between movies, genres, users... We can expect this model to give mediocre results.  

A more refined model includes the effect of the movie i ($\mathbf{Y}_{u,i} = \mu + b_{i} + \varepsilon_{u,i}$), with $b_{i}$ a term that would integrate the quality of the movie by computing the difference between the mean rating of each movie and the average rating for all movies.  
This model can be improved to $\mathbf{Y}_{u,i} = \mu + b_{i} + b_{u} + \varepsilon_{u,i}$, with $b_{u}$ a term that integrates the general "generosity" of each user.

Section that explains the process and techniques used, including data cleaning, data exploration and visualization, insights gained, and your modeling approach


# Results
Our naive model, that uses the calculated mean rating ($\hat{\mu}$ = `r round(mean_rating,2)` stars) and applies it to all predicted ratings, no matter the movie or user, has -- as one can expect -- a pretty mediocre RMSE (RMSE$_{n}$= `r round(rmse_naive,3)`). 
The movie-effect model improves sensibly the precision of the prediction, with RMSE$_{i}$= `r round(rmse_movie,3)`. The movie/user-effect model, while still quite basic, further improves the result, with RMSE$_{i,u}$= `r round(rmse_movie_user,3)`

Section that presents the modeling results and discusses the model performance

# Conclusion
Section that gives a brief summary of the report, its limitations and future work


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.